{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81c0b6e9",
   "metadata": {},
   "source": [
    "# Coulomb Matrix Descriptor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load modules and data\n",
    "\n",
    "! pip install dscribe\n",
    "import numpy as np\n",
    "import math, random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "from scipy.sparse import load_npz\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dscribe.descriptors import CoulombMatrix \n",
    "from ase import *\n",
    "from ase.build import molecule\n",
    "from ase.io import read, write\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3b54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import get_level  # needs to go here as wont have been downloaded earlier in\n",
    "\n",
    "def xyz_to_atoms(xyz):\n",
    "    f = io.StringIO()\n",
    "    f.write(xyz)\n",
    "    f.seek(0)  # had to add this in otherwise wont return to start of file once read in\n",
    "    atoms = read(f, format=\"xyz\")\n",
    "    return atoms\n",
    "\n",
    "print('Loading data...')\n",
    "df = pd.read_json('/content/drive/MyDrive/ColabNotebooks/Data/df_5k.json', orient='split')\n",
    "\n",
    "print('Generating `ase.Atoms` objects...')\n",
    "df['atoms'] = df['xyz_pbe_relaxed'].apply(xyz_to_atoms)\n",
    "\n",
    "print('Extracting HOMO, LUMO, BANDGAP from data...')\n",
    "df['HOMO'] = df.apply(lambda row: get_level(row, level_type='HOMO', subset='GOWO_at_PBE0_cbs'), axis=1)\n",
    "df['LUMO'] = df.apply(lambda row: get_level(row, level_type='LUMO', subset='GOWO_at_PBE0_cbs'), axis=1)\n",
    "df['BG'] = df['LUMO'] - df['HOMO']\n",
    "print('~ 2300 molecules do not have LUMO energy levels for this or any other `GOWO` level of theory.')\n",
    "\n",
    "# print('Splitting data set...')\n",
    "# train, test = train_test_split(df, test_size=0.2, random_state=20210817)\n",
    "# train_atoms, test_atoms = train['atoms'].to_list(), test['atoms'].to_list()\n",
    "\n",
    "print('Data Processing Complete')\n",
    "print('#', '-'*119)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fde1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets look at a random molecule represented with a Coulomb matrix \n",
    "y = df['xyz_pbe_relaxed'].shape[0]\n",
    "# print(df['xyz_pbe_relaxed'])\n",
    "print(y)\n",
    "\n",
    "rand_mol = random.randint(0, y)\n",
    "print(df['xyz_pbe_relaxed'].iloc[rand_mol])\n",
    "mol_of_choice = df['xyz_pbe_relaxed'].iloc[rand_mol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6e5a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_desc = CoulombMatrix(n_atoms_max=52, permutation='none', flatten=False)\n",
    "mol = df['atoms'].iloc[rand_mol]\n",
    "\n",
    "matrix = cm_desc.create(mol)\n",
    "print(matrix.shape)\n",
    "\n",
    "#Lets have a look at our random molecule and visualise the CM\n",
    "plt.figure()\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.imshow(matrix, origin=\"upper\", cmap='rainbow', vmin=-15, vmax=90, interpolation='nearest')\n",
    "plt.colorbar(fraction=0.046, pad=0.04).ax.tick_params(labelsize=20)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279f3d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['HOMO'].values, bins=20, density=False, facecolor='blue')\n",
    "plt.xlabel(\"Energy [eV]\")\n",
    "plt.ylabel(\"Number of molecules\")\n",
    "plt.title(\"Distribution of HOMO energies\")\n",
    "plt.show()\n",
    "\n",
    "## mean value of distribution\n",
    "print(\"Mean value of HOMO energies in OE62 dataset: %0.2f eV\" %np.mean(df['HOMO'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cdcbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=20210817)\n",
    "train_atoms, test_atoms = train['atoms'].to_list(), test['atoms'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52c7684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets visualise the data for each split to see if it resembles each other\n",
    "\n",
    "\n",
    "plt.hist(test['HOMO'].values, bins=20, density=False, alpha=0.5, facecolor='red', label='test set')\n",
    "plt.hist(train['HOMO'].values, bins=20, density=False, alpha=0.5, facecolor='gray', label='training set')\n",
    "plt.vlines((np.mean(train['HOMO'].values)), ymin=0, ymax=750, linestyles='--', color=\"white\")\n",
    "plt.vlines((np.mean(test['HOMO'].values)), ymin=0, ymax=150, linestyles='--')\n",
    "plt.title(\"HOMO energy distribution in test and train set\")\n",
    "plt.xlabel(\"Energy [eV]\")\n",
    "plt.ylabel(\"Number of molecules\")\n",
    "plt.legend()\n",
    "plt.savefig(\"/content/drive/MyDrive/ColabNotebooks/\"+str(\"HOMO.png\"), dpi=400)\n",
    "\n",
    "## mean value of distributions\n",
    "print(\"Mean value of HOMO energies in training set: %0.2f eV\" %np.mean(train['HOMO'].values))\n",
    "print(\"Mean value of HOMO energies in test set: %0.2f eV\" %np.mean(test['HOMO'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa1ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_numbers = df['atoms'].apply(lambda x: x.numbers)\n",
    "unique_atomic_numbers = set([a for b in atomic_numbers for a in b])\n",
    "max_num_atoms = atomic_numbers.apply(len).max()\n",
    "\n",
    "print(unique_atomic_numbers)\n",
    "print(max_num_atoms)\n",
    "\n",
    "feature_calc = CoulombMatrix(n_atoms_max=max_num_atoms)\n",
    "print('Generating features...')\n",
    "X_train, X_test = (np.vstack([feature_calc.create(a) for a in d]) for d in (train_atoms, test_atoms))\n",
    "print('Features generated.')\n",
    "\n",
    "\n",
    "y_train = train['HOMO'].values  # extract target value from dataframe\n",
    "y_test = test['HOMO'].values\n",
    "y_ave = np.average(y_train)\n",
    "\n",
    "#normalise data\n",
    "# y_train_tf = (y_train-y_ave)/y_ave\n",
    "# y_test_tf = (y_test-y_ave)/y_ave\n",
    "\n",
    "\n",
    "# # split the training data again intor training and cross validation sets\n",
    "# X_tr, X_cv, y_tr, y_cv = train_test_split(X_train, y_train_tf, test_size=0.2, random_state=1)\n",
    "\n",
    "# model = KernelRidge(kernel='rbf', alpha=0.01, gamma=0.01) \n",
    "# model.fit(X_tr, y_tr)\n",
    "\n",
    "# y_pred_tr = model.predict(X_tr)\n",
    "# y_pred_cv = model.predict(X_cv)\n",
    "# y_pred_ts = model.predict(X_test)\n",
    "\n",
    "# y_pred_tr = (y_pred_tr * y_ave)+y_ave\n",
    "# y_pred_cv = (y_pred_cv * y_ave)+y_ave\n",
    "# y_pred_ts = (y_pred_ts * y_ave)+y_ave\n",
    "\n",
    "\n",
    "# for s, pred, ref in zip(('train', 'cv', 'test'), (y_pred_tr, y_pred_cv, y_pred_ts), (y_tr, y_cv,y_test)):\n",
    "#   mse = mean_squared_error(ref, pred)\n",
    "#   r2 = r2_score(ref, pred)\n",
    "\n",
    "#   print(F'{s} : mse={mse:.3f}, r2={r2:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65ebcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up grids for alpha and gamma hyperparameters. \n",
    "# first value: lower bound; second value: upper bound; \n",
    "# third value: number of points to evaluate (here set to '3' --> '-2', '-1' and '0' are evaluated)\n",
    "# --> make sure to change third value as well when changing the bounds!\n",
    "alpha = np.logspace(-5, -2, 4)\n",
    "gamma = np.logspace(-5, -2, 4)\n",
    "\n",
    "\n",
    "cv_number = 5 ## choose into how many parts training set is divided for cross-validation\n",
    "kernel = 'laplacian' # select kernel function here ('rbf': Gaussian kernel, 'laplacian': Laplacian kernel)\n",
    "scoring_function = 'neg_mean_absolute_error' # it is called \"negative\" because scikit-learn interprets\n",
    "                                             # highest scoring value as best, but we want small errors\n",
    "\n",
    "## define settings for grid search routine in scikit-learn with above defined grids as input\n",
    "\n",
    "grid_search = GridSearchCV(KernelRidge(),  #machine learning method (KRR here)\n",
    "                           [{'kernel':[kernel],'alpha': alpha, 'gamma': gamma}], \n",
    "                           cv = cv_number, \n",
    "                           scoring = scoring_function, n_jobs=2,\n",
    "                           verbose=1000)  ## produces detailed output statements of grid search \n",
    "                                          # routine so we can see what is computed\n",
    "    \n",
    "# call the fit function in scikit-learn which fits the Coulomb matrices in the training set \n",
    "# to their corresponding HOMO energies.\n",
    "\n",
    "from datetime import datetime\n",
    "start = datetime.now()\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "finish = datetime.now()\n",
    "total_time = finish - start \n",
    "print(\"It took how long?\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb27bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(-means, stds, grid_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d19d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "#pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "pvt = pd.pivot_table(results, values='mean_test_score', \n",
    "                     index='param_gamma', columns='param_alpha')\n",
    "heatmap = sns.heatmap(-pvt, annot=True, cmap='viridis', cbar_kws={'label': \"Mean absolute error [eV]\"})\n",
    "figure = heatmap.get_figure()\n",
    "plt.savefig(\"/content/drive/MyDrive/ColabNotebooks/\"+str(\"laplacian2.png\"), dpi=400)\n",
    "\n",
    "\n",
    "print(\"The best combinations of parameters are %s with a score of %0.3f eV on the validation set.\"\n",
    "      % (grid_search.best_params_, -grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff32752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted HOMO energies for all test molecules\n",
    "\n",
    "y_pred = grid_search.predict(X_test) # scikit-learn automatically takes the best combination\n",
    "                                     # of hyperparameters from grid search\n",
    "\n",
    "print(\"Mean absolute error on test set: %0.3f eV\" %(np.abs(y_pred-y_test)).mean())\n",
    "print(\"Mean square error on test set: %0.3f eV\" % mean_squared_error(y_test, y_pred)\n",
    "# do the regression plot\n",
    "plt.plot(y_pred,y_test,marker='.')\n",
    "plt.plot([np.min(y_test),np.max(y_test)], [np.min(y_test),np.max(y_test)], '-')\n",
    "plt.ylabel('prediicted HOMO energy [eV]')\n",
    "plt.xlabel('reference HOMO energy [eV]')\n",
    "lst_best_params= list(grid_search.best_params_.values())\n",
    "plt.title(\"G0W0 HOMO, KRR-Laplacian, alpha=0.01, gamma=1e-05\")\n",
    "plt.savefig(\"/content/drive/MyDrive/ColabNotebooks/\"+str(\"laplacian.png\"), dpi=400)\n",
    "print(\"R^2 score on test set: %.3f\" % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45994a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean square error on test set: %0.3f eV\" % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d8e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5782f4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15421ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee9a27a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
